# ğŸ““ Journal â€” September 20, 2025 â€” Week 2 Data Modeling & Testing

## ğŸ“‹ Table of Contents
   1. [ğŸ“˜ What I Learned](#1--what-i-learned)
      - [ğŸ”§ Tools](#-tools)
      - [âš™ï¸ Main Project Process](#ï¸-main-project-process)
      - [ğŸ“š General Data Engineering Concepts](#-general-data-engineering-concepts)
   2. [ğŸ“ New Vocabulary](#2--new-vocabulary)
   3. [ğŸ§  Data Engineering Mindset](#3--data-engineering-mindset)
   4. [ğŸ—‚ï¸ Decisions & Assumptions](#4--decisions--assumptions)
   5. [â“ Open Questions](#5--open-questions)
   6. [âœ… Next Actions](#6--next-actions)
   7. [ğŸ”— Artifacts & Links](#7--artifacts--links)
      - [ğŸ“š Data Engineering](#-data-engineering)
   8. [âœ¨ Mini Reflection](#-mini-reflection)
   9. [ğŸ”¥ BONUS: Meme of the Day](#-bonus-meme-of-the-day)


---

## 1) ğŸ“˜ What I Learned


   ### âš™ï¸ Main Project Process

   **Documentation of last Saturday's project here for future reference:**
   * [September 20 Project Chinook Ingestion on Remote Server](  https://github.com/jynmargo/ftw-de-journal/blob/main/templates/personal/sept20-project-chinoook-ingestion.md)

   1. Data Pipeline Setup â€“ Built DLT pipeline to extract Chinook data to ClickHouse
   2. Data Modeling â€“ Changed naming, followed standars as instructed
   3. Created fact and dimension tables and connected to Metabase.


   ### ğŸ“š General Data Engineering Concepts

   - Starting from scratch helps DEs to understand things better
      - Even if companies usually have DE / pipeline setups already
   - Important to confidently articulate the flow, how did you ingest, flow, aggregation
      - Talk in pipelines:
         Ingest to raw, clean, move into mart
      - âš ï¸ In visualizations, check **Edge cases** (what looks sus? these are opportunities for trade offs)

   ### Sandbox
   - Ephemeral, meant to be exploratory
   - Table vs Views
   - Mechanical Data

   ### Group Assignment recap
   - When is it the right time to create views vs tables?
   #### DBeaver 
   - used to check the flow
   #### Metabase 
   - meant for end users only. Data engineers usually donâ€™t use Metabase.
   - But if included in dbt script -> permanent (for prod setup)

   #### Misc Concepts:
   - Engine = Memory â€“ shutdown memory -> data disappears
   - Saving data in sandbox âŒ not recommended
   - In DE, what's important is 'Did you do it? ğŸ”'
      - Better to include -> data mapping, flow, pipeline design on slide presentations (MOVEMENT OF DATA)
   - Documentation â€“> big part of data engineering (everything in docs)
   - What do you document?
   - Github is acquired by Microsoft
   - YAML
      - has been popular the Past 5 years
      - Data Modeling
         - How data is structured
         - OLTP vs OLAP
         - Data model in warehouse
      - Cubes -> pre-aggregation, predetermined SQL commands
      - RDBMS
         - (Mas pogi: ClickHouse)



   ### Business Perspective
   (Gives context on data)
	
   - When getting data, identify categories. Example: Female, Male, Prefer not to say -> What model are we trying to build?
   - If I were starting a business and selling something, what actions would I take to make it happen?
   - 'If thereâ€™s a customer who wants to buy. I need to make sure I can sell to them.'
   - ğŸ’° Goal: Make the sale happen as fast as possible.

   ### Entity Relationship Model
   - Tables
   - Attributes
   - Relationships - SET OF BUSINESS RULES 
   - How SQL was born
      - with relational modeling ()
      - YAML - dictionary (rows and columns)
      - Graphs - represent data

   ### Normalization
   - Safety checks for dirty water ğŸ’§
   - 3RD NORMAL FORM
      - Non-key attributes should not depend on another non-key attributes
      - Gform -> try to model -> lalabas issues
   - 1NF 
      - atomic
   - 2NF
      - nonkey should depend on whole key

   ### Data Modeling layer
   - Conceptual -> Logical -> Physical
   - DE's work propagates -> if pangit model -> pangit upstream

   ### Modeling Approaches
   - Kimball / Dimensional - Fact + Dimensions for BI & Dashboards
   - Inmon / 3nf edw
   - Data Vault
   - Lakehouse / Medallion
   - Wide Table / OBT
   - Sir myk mentioned a 5-10k worth Dimensional modeling book
      (Sir Myk will recommend books soon, and I am curious to know more about them)





   
## 2) ğŸ“ New Vocabulary

- Schema - modeling 
- Inmon - a top-down approach to data warehousing that creates a centralized, normalized Enterprise Data Warehouse (EDW)
- Kimball - a data warehousing approach that uses a dimensional model, typically a star schema, to provide business users with a fast, user-friendly, and understandable view of data for business intelligence and analytics

---

## 3) ğŸ§  Data Engineering Mindset

- Data Engineers
 - They should expect that things are meant to scale
 - They are meant to be used by a lot of people, which is why documentation is so important.
- â—ï¸Focus here: data mapping, flow, pipeline design. I keep forgetting this because having a ui/ux designing background makes me enjoy spending more time on designing and creating appealing visuals. That is not the job of a DE.
- DOCUMENT, DOCUMENT, DOCUMENT - I cannot stress this enough


---

## 4) ğŸ—‚ï¸ Decisions & Assumptions

- Apart from the tools needed to be used, I need to study more on the business aspect to fully grasp how DEs take part in decision-making.

---

## 5) â“ Open Questions

- What data are safe to ask AI or what data are safe to push on public github repositories?
(Safe to share: sample code, public datasets, open-source APIs, generic config templates.

Not safe to share:
   - Real usernames/passwords
   - API keys / tokens
   - Internal server IPs or connection strings (unless theyâ€™re just public demo servers like Chinook training DBs)
   - Proprietary business data

---

## 6) âœ… Next Actions

* [ ] Play around with sandbox schema 
* [ ] Create a documentation for the projects
* [ ] Spend some time on DSA in Python on Datacamp. Graduating in CS and forgetting it is a shame. I need to fix that before it haunts me.
* [ ] Know where DSA takes place in Data Engineering 

---

## 7) ğŸ”— Artifacts & Links

### ğŸ“š Data Engineering

I have already listed these in my previous journal, but if you're here, I recommend checking them out too as these have helped me as well. :)
* [Chinook Database](https://github.com/lerocha/chinook-database)
* [Awesome Data Engineering resources](https://github.com/igorbarinov/awesome-data-engineering)
* [Dataset Repository](https://archive.ics.uci.edu/dataset/9/auto+mpg)

### âœï¸ Markdown Tools

* [Markdown Preview](https://markdownlivepreview.com/)
* [Badge Generator](https://alexandresanlim.github.io/Badges4-README.md-Profile/#/?id=%e2%9a%a1-database-%f0%9f%94%9dmenu)




---

## âœ¨ Mini Reflection

As of now, I have experienced loading data in marts using dlt and dbt from raw csv files. 
I know that there are still a lot to learn on being a Data Engineer. I'm looking forward to the data testing, and trying out other ways to source data (such as using APIs), because it checks a life goal in my bucketlist, which is to work with APIs in data engineering (because it sounds complicated, and I find thrill in being able to challenge myself to do things I think that are hard.)

I really appreciate my groupmates in the last project we did, and I'm looking forward to doing more challenges with them (She-Ahn, ate Wish, ate CJ, & ate Rizza). They are very helpful, cooperative, and supportive, with each one having their own strengths upon us doing a workflow of the Auto_mpg dataset. I get to learn more stuff I don't know in data from the casual conversations we had and those are priceless.

I will start documenting the processes of projects starting now as I am inspired by Shi.ai and as Sir Myk keeps on reminding us.

Also as I have mentioned I still need to brush up my DSA understanding through this week's datacamp, as I might have forgotten a lot of it.

---

## ğŸ”¥ BONUS: Meme of the Day

Mikay thinks it's getting real now~ 

from her front-end/ui/ux/dashboarding comfort zone âœ¨ğŸŒˆğŸ¦‹ğŸ¤ğŸ‡  
to now exploring the deeper waters ğŸ‘¹ ğŸ²ğŸ™ğŸ¦–

![hehehe](https://miro.medium.com/v2/1*cl5P-DYvLBW03XLRYiF6LQ.png)

Dashboards look simple on the surface.

But underneath, thereâ€™s a ton of invisible work (pipelines, cleaning, modeling) done by data engineers to make sure the dashboard shows something meaningful and trustworthy.

