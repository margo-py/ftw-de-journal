# üìì Journal ‚Äî October 4, 2025 ‚Äî Week 4

## üìã Table of Contents

1. [üìò What I Learned](#1--what-i-learned)
   * [‚öôÔ∏è Main Project Process](#Ô∏è-main-project-process)
   * [üìö General Data Engineering Concepts](#-general-data-engineering-concepts)
2. [üìù New Vocabulary](#2--new-vocabulary)
3. [üß† Data Engineering Mindset](#3--data-engineering-mindset)
4. [üóÇÔ∏è Decisions & Assumptions](#4--decisions--assumptions)
5. [‚ùì Open Questions](#5--open-questions)
6. [‚úÖ Next Actions](#6--next-actions)
7. [üîó Artifacts & Links](#7--artifacts--links)
8. [‚ú® Mini Reflection](#-mini-reflection)

---

## 1) üìò What I Learned

### ‚öôÔ∏è Main Project Process
- Working with groupings and larger datasets
- Transitioned from Snowflake ‚ùÑÔ∏è schema to Star Schema ‚≠êÔ∏è for OULAD dataset
- Realized Star Schema was better suited for simple business questions (fewer joins needed)
- Building an Entity Relationship Diagram first is extremely helpful

### üìö General Data Engineering Concepts

**Data Quality is KING üëë**
- Only 1% of companies do data quality properly
- If done well, you become a money-making data engineer
- Create data that people actually trust
- Stakeholders always ask: "Is this data real/accurate?"
- Low quality data ruins everything (dashboards, ML models, LLMs, all AI systems)
- Good visualization with bad data = useless üëé

**5 Dimensions of Data Quality:**
1. Accuracy
2. Completeness
3. Reliability
4. Relevancy
5. Timeliness

**Data Quality Framework:**
- Data SLA (Service Level Agreements)
- Long-term quality decision making
- Set thresholds (e.g., 90% quality target)
- Dashboard presentation: "Is this trustworthy? Notice our target threshold is 90%"

**Shared Data Responsibility:**
- RACI Matrix (Responsible, Accountable, Consulted, Informed)
- Data Steward (executioner of data owner's decisions)
- Outside typical DE role, but important for collaboration

**Data Warehouse Architecture:**
- Medallion: Raw -> Clean -> Mart -> Visualization
- Data Quality Checks at each layer
- Best practices reduce errors

---

## 2) üìù New Vocabulary

**Change Management**
- Process of managing changes in data systems

**Layered Checks**
- Quality checks at Raw, Mart, and Report levels

**Data Quality Goals & Inputs:**
- Goal: Is the data healthy?
- Input: `dq_check_results` table + optional supplementary data
- Key questions: Is it green (passing)? Is it red (failing)?
- How many nulls entered raw vs clean layers?

**Minimal Logging Schema:**
```sql
-- Separate tables for tracking quality
dq_failed_samples (
    check_id INT,
    dataset STRING,
    rule STRING,
    sample JSON,
    executed_at DATETIME
)
```

**Populate Results Example:**
```sql
INSERT INTO dq_check_results
SELECT 
    101 AS check_id,
    'studentAssessment' AS table_name,
    'score_range' AS check_name,
    IF(countIf(score < 0 OR score > 100) = 0, 'PASS', 'FAIL') AS status,
    countIf(score < 0 OR score > 100) AS metric_value,
    'Score must be between 0-100' AS metric_text
FROM studentAssessment;
```

**Starting Point for Metrics:**
- 1-3 key metrics per table as baseline
- Build from there based on business needs

---

## 3) üß† Data Engineering Mindset

- **Data has history** - understand lineage and transformations
- **Problem framing first** - define what you're solving before building
- **Trust is everything** - technical skills mean nothing without trustworthy data
- **Iterative improvement** - start simple (Star Schema), optimize later if needed

---

## 4) üóÇÔ∏è Decisions & Assumptions

**Schema Decision:**
- **Decision:** Use Star Schema instead of Snowflake Schema for OULAD
- **Reasoning:** Simple business questions don't require complex joins
- **Assumption:** Performance and maintainability > theoretical normalization

**Data Quality Threshold:**
- Set 90% as acceptable quality threshold
- Anything below triggers investigation

---

## 5) ‚ùì Open Questions

- **When to use Star Schema vs Snowflake Schema?**
  - When is Snowflake justified vs overengineering?
  - Current understanding: Star for simple queries, Snowflake when normalization benefits outweigh join complexity

- **How deep should quality checks go?**
  - What's the right balance between comprehensive checks and performance?

---

## 6) ‚úÖ Next Actions

- [ ] Improve presentation skills for data findings
- [ ] Practice explaining quality metrics to non-technical stakeholders
- [ ] Implement data quality checks for OULAD dataset
- [ ] Create documentation for schema decisions
- [ ] Find where data is most appreciated in OULAD dataset for demo purposes

---

## 7) üîó Artifacts & Links

* [OULAD Dataset](https://archive.ics.uci.edu/dataset/349/open+university+learning+analytics+dataset)
* [Shields.io Badge Generator](https://shields.io/)
* [DB Diagram Tool](https://dbdiagram.io/)

[![dbdiagram](https://img.shields.io/badge/dbdiagram-blue?logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij48cGF0aCBmaWxsPSJ3aGl0ZSIgZD0iTTEyIDJDNi40OCAyIDIgNi40OCAyIDEyczQuNDggMTAgMTAgMTAgMTAtNC40OCAxMC0xMFMxNy41MiAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPjwvc3ZnPg==)](https://dbdiagram.io/)

---

## ‚ú® Mini Reflection

I'm getting the hang of Data Engineering! The medallion architecture (Raw -> Clean -> Mart - Visualization) is starting to click.

**Key Learning: Schema Design**
Working with bigger data was nerve-wracking but educational. I learned more about normalization and when to apply Star vs Snowflake schemas. OULAD was suitable for both, but after, Snowflake Schema was the pragmatic choice.

**Most Important Takeaway:**
Data Quality is everything. Without it, all the fancy architecture and visualizations are worthless. Trust is what separates good data engineers from the rest.



---

## üî• BONUS: Meme
![](https://preview.redd.it/behind-every-clean-dataset-is-a-data-engineer-turning-chaos-v0-nzl56zh8ev5f1.png?width=640&crop=smart&auto=webp&s=4a0a1c45588c7a644f98248d7dbd0c7d7732bf50)
