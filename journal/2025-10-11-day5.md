# ğŸ““ Journal - October 11, 2025 - Week 5 Web Scraping, Data Ethics, and Real-World Data Engineering Tips

## ğŸ“‹ Table of Contents

1. [ğŸ“˜ What I Learned](#1--what-i-learned)

   * [ğŸ•¸ï¸ Data Collection & Web Scraping](#ï¸-data-collection--web-scraping)
   * [ğŸ“Š Data Shapes, Types & Formats](#-data-shapes-types--formats)
   * [ğŸ’» Web API Ingestion & Pandas](#-web-api-ingestion--pandas)
   * [âš–ï¸ Data Ethics & Real-World Tips](#ï¸-data-ethics--real-world-tips)
2. [ğŸ“ New Vocabulary](#2--new-vocabulary)
3. [ğŸ§  Data Engineering Mindset](#3--data-engineering-mindset)
4. [ğŸ—‚ï¸ Decisions & Assumptions](#4--decisions--assumptions)
5. [â“ Open Questions](#5--open-questions)
6. [âœ… Next Actions](#6--next-actions)
7. [ğŸ”— Artifacts & Links](#7--artifacts--links)
8. [âœ¨ Mini Reflection](#-mini-reflection)

---

## 1) ğŸ“˜ What I Learned

### ğŸ•¸ï¸ Data Collection & Web Scraping

ğŸ•˜ *9:14 AM*

* The hardest topic so far.
* Sir Myk suggested not to solely rely on **web scraping** for capstone projects.
* Day 5 = Skills for Capstone + Web Scraping 101
* FTW Bootcamp is **not spoonfeeding** - the reality is job requirements vary, weâ€™re pinpointing common skills.

**Lesson Proper:**

* **Agenda for Today:**

  * â€œData in the Wildâ€ -> collecting & handling data responsibly
  * Data works in a lifecycle:

    1. Something happens (Event)
    2. Itâ€™s represented as data (like temperature)
    3. Sensors measure it -> numbers
  * Example: Earthquake detection in Davao - sensors capture readings


**How websites work:**

* Browser (client) requests from server -> gets HTML back.
* Browser renders HTML visually; scraping = reading data, not viewing.
* Every website structure is different -> parsing needed.
* HTML = DOM tree ğŸŒ³ - BeautifulSoup parses that tree.
* JavaScript makes it dynamic, thatâ€™s where hidden APIs live (like Lazada).

**Web Scraping Levels:**

1. Static (HTML) -> `requests + BeautifulSoup`
2. Dynamic (JS/API) -> inspect Network -> XHR -> JSON
3. No API -> use **Headless browser (Playwright)**

---

### ğŸ“Š Data Shapes, Types & Formats

**Data as Different Shapes:**

* Tabular -> CSV/SQL
* Hierarchical -> JSON/XML
* Graph -> relationships (Neo4j)
* Time Series -> sensor data (Parquet/Influx)
* Geospatial -> map coords (GeoJSON, Shapefile)

> â€œFocus on the **flow** of the data, not the tools.â€ - Sir Myk

**Data Types & Semantics:**

* Primitive, Temporal, Categorical
* Depends on database - ex: Tableau or PowerBI use â€œmodelingâ€ (location, date).
* Representation affects efficiency - string timestamps = heavy.
* CSV = readable but large; JSON = flexible; Parquet = analytics-ready.
* Analysts love CSVs, but engineers think in **pipelines** - automation, scalability.

---

### ğŸ’» Web API Ingestion & Pandas

**Afternoon Session:**

* Virtual env (`venv`) keeps environment isolated.
* Sir Myk says **UV** is now the best package manager.
* Pandas = best friend for small data work.
* SQL = foundation of data engineering.
* Extract small slices (use LIMIT, filters).
* Validate row counts and schemas.
* Pandas loads everything into memory (inefficient for GB-scale).
* Use **Ibis** for larger data -> same syntax, runs efficiently.

**APIs:**

* REST API = machines talking to machines.
* Look for â€œendpointsâ€ and pass credentials if required.
* Learn to read API docs and watch for pagination, rate limits, retries.
* Always log requests with timestamps and durations.
* Example API: [Open Meteo](https://open-meteo.com/) - fetch temperature in Manila ğŸŒ¡ï¸

**Key Insight:**

> â€œIf you can open it in Chrome, you can automate it - but websites fight back.â€
> Use APIs when possible. Web scraping is the last resort.

---

### âš–ï¸ Data Ethics & Real-World Tips

* Just because we *can* collect, doesnâ€™t mean we *should*.
* Data ethics = unseen but crucial.
* Collect with **consent and awareness.**
* Balance business goals with privacy, safety, dignity.
* **Shared responsibility**: data collection, transformation, reporting.
* Avoid: lack of transparency, ignoring bias.
* Bias isnâ€™t always bad - just know where it exists.

**Real World Tips:**

1. Continuous learning
2. Build a portfolio
3. Find your focus (DE/DA)
4. Practice explaining data clearly
5. Build a career - not just a project

---

## 2) ğŸ“ New Vocabulary

* **Headless Browser:** browser with no GUI (Playwright)
* **API Endpoint:** data access URL
* **Pagination:** APIâ€™s next/offset system for pages
* **Data Minimization:** only collect whatâ€™s needed
* **Sensor Data:** raw values measured from real-world events

---

## 3) ğŸ§  Data Engineering Mindset

* Mistakes are allowed - theyâ€™re part of growth.
* Logic and creativity work together.
* I respect logic and math deeply, but creativity keeps me grounded.
* The goal is **trustworthy, ethical, and resilient** data pipelines.

---

## 4) ğŸ—‚ï¸ Decisions & Assumptions

* Prefer APIs over scraping whenever possible.
* If scraping, use **Playwright headless mode** for practice only.
* Store data ethically and document sources.
* Use Pandas for small datasets, Ibis or SQL for scale.

---

## 5) â“ Open Questions

* When is web scraping legally and ethically okay?
* How to manage bias transparently in datasets?
* When should I transition from Pandas to Ibis or SQL?

---

## 6) âœ… Next Actions

* [ ] Practice Playwright for dynamic scraping (Lazada example)
* [ ] Try connecting Open Meteo API -> save JSON -> CSV
* [ ] Add logging for API requests (timestamp + duration)
* [ ] Explore Ibis and DuckDB for scalable data analysis
* [ ] Start documenting capstone data flow early

---

## 7) ğŸ”— Artifacts & Links

* [BeautifulSoup GitHub](https://github.com/wention/BeautifulSoup4)
* [Playwright Docs](https://playwright.dev/python/)
* [Ibis Project](https://ibis-project.org/)
* [Pandas IO Docs](https://pandas.pydata.org/docs/user_guide/io.html)
* [Open Meteo API](https://open-meteo.com/)


---

## âœ¨ Mini Reflection

I realized Iâ€™m actually growing a lot. I am also slowly realizing where my skills could fit in the big picture of Data Engineering or anything related. I enjoy building stuff, but struggle with the nitty-gritty. I think I may be doing best in building and setting up the tools, but as for the data cleaning and spotting data quality issues, this is an area I need to work on more.

Also, I used to think my creativity didnâ€™t belong in data work, but I was wrong.
Data Engineering *needs* creativity - from building pipelines to solving real-world problems.

Itâ€™s okay to make mistakes.
Every bug and failed scrape taught me something.

> â€œFocus on the flow - itâ€™s easier, not the tools.â€
> â€œWeb scraping is the last resort - APIs are your friends.â€

Iâ€™m proud that I stayed awake despite not having any sleep last night, and learned a lot this today.

![](https://preview.redd.it/how-to-benefit-from-lean-data-quality-v0-fhm25s6gtuzd1.jpeg?auto=webp&s=7a9f40339bdc2e33ec1c6312008b44c33a5d527f)

